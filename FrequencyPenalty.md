

# ğŸ¯ **What is Frequency Penalty?**

**Frequency penalty reduces the score of words that the model has already used many times.**

Meaning:

* If a word repeats often â†’ its probability decreases.
* This helps avoid repetition in answers.

---

# ğŸ§  Why do we need it?

LLMs sometimes repeat phrases like:

* â€œThe reason isâ€¦â€
* â€œIn conclusionâ€¦â€
* â€œThe main point isâ€¦â€

Frequency penalty **forces the model to use different words** instead of repeating the same one again and again.

---

# âœ” Example (Very Easy)

User input:
ğŸ‘‰ *â€œExplain RAG.â€*

Without frequency penalty:
â€œRAG works by retrieving relevant chunks and generating answers based on those chunks. These chunks help the model generate better answers because chunks contain context.â€

Repeats **â€œchunksâ€** too much.

---

### After applying **frequency penalty = 1.0**

â€œRAG retrieves relevant sections of text and then the model uses that context to produce a final answer.â€

âœ” Repetition reduced
âœ” More diverse words

---

# ğŸ”¢ How it works internally

Each time the model uses a word,
â†’ a penalty is added to that wordâ€™s probability.
â†’ the model prefers other words.

---

# ğŸ” Difference Between Frequency Penalty vs Presence Penalty

| Feature  | Frequency Penalty                    | Presence Penalty                         |
| -------- | ------------------------------------ | ---------------------------------------- |
| Purpose  | Reduce repeated words                | Encourage *introducing new topics/words* |
| Based on | How many times word already appeared | Whether the word appeared at least once  |
| Effect   | Less repetition                      | More variety / new ideas                 |

**Frequency penalty = reduce overuse**
**Presence penalty = encourage diversity**

---

# ğŸ¯ Summary

â€œFrequency penalty reduces how often an LLM repeats the same word.
The more times a word was already used, the more the model penalizes it, encouraging varied wording."

---
